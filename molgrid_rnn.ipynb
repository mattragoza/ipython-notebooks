{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys, time\n",
    "import molgrid\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "sns.set_palette('bright')\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.265483856201172, 36.588661193847656, 34.86753845214844)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_file, data_root = '/home/mtr22/cnn/gan/data/carbon.types', '/home/mtr22/cnn/gan/data/'\n",
    "data_file, data_root = '/home/mtr22/cnn/gan/data/single.types', '/home/mtr22/PDBbind/refined-set/'\n",
    "\n",
    "data_loader = molgrid.ExampleProvider(molgrid.NullIndexTyper(),\n",
    "                                      molgrid.defaultGninaLigandTyper,\n",
    "                                      make_vector_types=True,\n",
    "                                      data_root=data_root,\n",
    "                                      shuffle=True)\n",
    "data_loader.populate(data_file)\n",
    "\n",
    "elems = ['C','C','C','C','Br','Cl','Fl','N','N','O','O','S','P','Zn','Li'] #use Li for dummy\n",
    "\n",
    "n_types = molgrid.defaultGninaLigandTyper.num_types()\n",
    "radii = np.array(list(molgrid.defaultGninaLigandTyper.get_type_radii()))\n",
    "\n",
    "batch = data_loader.next_batch(1)\n",
    "tuple(batch[0].coord_sets[1].center())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolNet(nn.Module):\n",
    "    '''\n",
    "    Base class for a model that generates molecular structures.\n",
    "    '''\n",
    "    def __init__(self, n_atoms, n_types):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_atoms = n_atoms\n",
    "        self.n_types = n_types\n",
    "        \n",
    "    def to(self, device):\n",
    "        ret = super(MolNet, self).to(device)\n",
    "        self.device = device\n",
    "        return ret\n",
    "\n",
    "\n",
    "class MolStruct(MolNet):\n",
    "    '''\n",
    "    A directly optimizable molecular structure.\n",
    "    '''\n",
    "    def __init__(self, n_atoms, n_types, *args):\n",
    "        super().__init__(n_atoms, n_types)\n",
    "        \n",
    "        self.coords = nn.Parameter(torch.randn(n_atoms, 3))\n",
    "        self.types = nn.Parameter(torch.randn(n_atoms, n_types+1))\n",
    "        \n",
    "    def forward(self, input, temp=0.0):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        coords = self.coords.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        types = F.softmax(self.types.unsqueeze(0).repeat(batch_size, 1, 1), dim=-1)\n",
    "     \n",
    "        if temp:\n",
    "            coords += temp * torch.randn(batch_size, self.n_atoms, 3, device=self.device)\n",
    "    \n",
    "        return coords, types\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    \n",
    "    def __init__(self, *shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.view(self.shape)\n",
    "\n",
    "\n",
    "class Conv3dEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dims, n_output):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_input = input_dims[0]\n",
    "        last_layer_size = 128 * input_dims[1]//16 \\\n",
    "                              * input_dims[2]//16 \\\n",
    "                              * input_dims[3]//16\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(n_input, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True), nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True), nn.MaxPool3d(2),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True), nn.MaxPool3d(2),\n",
    "            nn.Conv3d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True), nn.MaxPool3d(2),\n",
    "            Reshape(-1, last_layer_size),\n",
    "            nn.Linear(last_layer_size, n_output),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "    \n",
    "class MolgridCNN(MolNet):\n",
    "    '''\n",
    "    A model that takes a molgrid as input, encodes it to a latent\n",
    "    vector with a CNN, and then decodes it as a molecular structure\n",
    "    using only feedforward layers.\n",
    "    '''\n",
    "    def __init__(self, n_atoms, n_types, dims, n_latent, var_coords=False):\n",
    "        super().__init__(n_atoms, n_types)\n",
    "        \n",
    "        self.enc = Conv3dEncoder(dims, n_latent)\n",
    "        \n",
    "        self.fc_latent2 = nn.Linear(n_latent, n_latent)\n",
    "        self.fc_coords = nn.Linear(n_latent, n_atoms*3)\n",
    "        self.fc_types = nn.Linear(n_latent, n_atoms*(n_types+1)) # include dummy type\n",
    "        \n",
    "        self.var_coords = var_coords\n",
    "        if var_coords:\n",
    "            self.fc_coords_logstd = nn.Linear(n_latent, n_atoms*3)\n",
    "    \n",
    "    def forward(self, input, temp=0.0):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        # get latent encoding of input density from CNN\n",
    "        x = self.enc(input)\n",
    "        x = self.fc_latent2(x)\n",
    "        \n",
    "        coords = self.fc_coords(x).view(batch_size, self.n_atoms, 3)\n",
    "        types = F.softmax(self.fc_types(x).view(batch_size, self.n_atoms, -1), dim=-1)\n",
    "        \n",
    "        if temp:\n",
    "            coords += temp * torch.randn(batch_size, self.n_atoms, 3, device=self.device)\n",
    "            \n",
    "        if self.var_coords:\n",
    "            z = torch.randn(batch_size, self.n_atoms, 3, device=self.device)\n",
    "            coords += torch.exp(self.fc_coords_logstd(x).view(batch_size, self.n_atoms, 3)) * z\n",
    "        \n",
    "        return coords, types\n",
    "        \n",
    "\n",
    "class MolgridRNN(MolNet):\n",
    "    '''\n",
    "    A model that takes a molgrid as input, encodes it to a latent\n",
    "    vector with a CNN, and then decodes it as a molecular structure\n",
    "    with an LSTM.\n",
    "    '''\n",
    "    def __init__(self, n_atoms, n_types, dims, n_latent, var_coords=False):\n",
    "        super().__init__(n_atoms, n_types)\n",
    "        \n",
    "        self.enc = Conv3dEncoder(dims, n_latent)\n",
    "        self.fc_latent2 = nn.Linear(n_types+4, n_latent)\n",
    "        self.lstm = nn.LSTM(n_latent, n_latent)\n",
    "        self.fc_coords = nn.Linear(n_latent, 3)\n",
    "        self.fc_types = nn.Linear(n_latent, n_types+1) # include dummy type\n",
    "        \n",
    "        self.var_coords = var_coords\n",
    "        if var_coords:\n",
    "            self.fc_coords_logstd = nn.Linear(n_latent, 3)\n",
    "    \n",
    "    def forward(self, input, temp=0.0):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        # get latent encoding of input density from CNN\n",
    "        x = self.enc(input).unsqueeze(0)\n",
    "        \n",
    "        # accumulate output atoms in tensors, using batch-first dim order\n",
    "        coords = torch.zeros(batch_size, 0, 3, device=self.device)\n",
    "        types = torch.zeros(batch_size, 0, n_types+1, device=self.device)\n",
    "        \n",
    "        lstm_state = None\n",
    "        for i in range(self.n_atoms):\n",
    "            \n",
    "            _, lstm_state = self.lstm(x, lstm_state)\n",
    "            lstm_h, lstm_c = lstm_state\n",
    "            \n",
    "            xyz = self.fc_coords(lstm_h)\n",
    "            t = F.softmax(self.fc_types(lstm_h), dim=-1)\n",
    "            \n",
    "            if temp:\n",
    "                xyz += temp * torch.randn(1, batch_size, 3, device=self.device)\n",
    "            \n",
    "            if self.var_coords:\n",
    "                z = torch.randn(1, batch_size, 3, device=self.device)\n",
    "                xyz += torch.exp(self.fc_coords_logstd(lstm_h).view(1, batch_size, 3)) * z\n",
    "            \n",
    "            coords = torch.cat((coords, xyz.permute(1, 0, 2)), dim=1)\n",
    "            types = torch.cat((types, t.permute(1, 0, 2)), dim=1)\n",
    "            \n",
    "            if i+1 < self.n_atoms:\n",
    "                xyzt = torch.cat((xyz, t), dim=-1)\n",
    "                x = F.relu(self.fc_latent2(xyzt))\n",
    "        \n",
    "        return coords, types\n",
    "\n",
    "\n",
    "class MolgridAttn(MolNet):\n",
    "    '''\n",
    "    A model that takes a molgrid as input, encodes it to a latent\n",
    "    vector with a CNN, and then decodes it as a molecular structure\n",
    "    using attention.\n",
    "    '''\n",
    "    def __init__(self, n_atoms, n_types, dims, n_latent, var_coords=False):\n",
    "        super().__init__(n_atoms, n_types)\n",
    "        \n",
    "        self.enc = Conv3dEncoder(dims, n_latent)\n",
    "        \n",
    "        self.att = Attention()\n",
    "        d_k = d_v = n_latent//4\n",
    "        \n",
    "        self.fc_Q_oo = nn.Linear(n_types+4, d_k)\n",
    "        self.fc_K_oo = nn.Linear(n_types+4, d_k)\n",
    "        self.fc_V_oo = nn.Linear(n_types+4, d_v)\n",
    "        \n",
    "        self.fc_Q_io = nn.Linear(d_k, d_k)\n",
    "        self.fc_K_io = nn.Linear(n_latent, d_k)\n",
    "        self.fc_V_io = nn.Linear(n_latent, d_v)\n",
    "        \n",
    "        self.fc_coords = nn.Linear(d_k, 3)\n",
    "        self.fc_types = nn.Linear(d_k, n_types+1) # include dummy type\n",
    "        \n",
    "        self.var_coords = var_coords\n",
    "        if var_coords:\n",
    "            self.fc_coords_logstd = nn.Linear(d_k, 3)\n",
    "    \n",
    "    def forward(self, input, temp=0.0):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        # get latent encoding of input density from CNN\n",
    "        x = self.enc(input).unsqueeze(1)\n",
    "        \n",
    "        # accumulate output atoms in tensors\n",
    "        coords = torch.zeros(batch_size, self.n_atoms, 3, device=self.device)\n",
    "        types = torch.zeros(batch_size, self.n_atoms, n_types+1, device=self.device)\n",
    "        \n",
    "        xyz = torch.zeros(batch_size, 1, 3, device=self.device)\n",
    "        t = torch.zeros(batch_size, 1, self.n_types+1, device=self.device)\n",
    "        #t[:,:,-1] = 1\n",
    "    \n",
    "        xyzt = torch.cat((xyz, t), dim=-1) # (batch_size, 1, n_types+4)\n",
    "        ct = torch.cat((coords, types), dim=-1) # (batch_size, n_atoms, n_types+4)\n",
    "        \n",
    "        for i in range(self.n_atoms):\n",
    "            \n",
    "            Q_oo = self.fc_Q_oo(xyzt) # (batch_size, 1, d_k)\n",
    "            K_oo = self.fc_K_oo(ct) # (batch_size, n_atoms, d_k)\n",
    "            V_oo = self.fc_V_oo(ct) # (batch_size, n_atoms, d_v)\n",
    "            a_oo = self.att(Q_oo, K_oo, V_oo) # (batch_size, 1, d_v) TODO mask\n",
    "                     \n",
    "            Q_io = self.fc_Q_io(a_oo) # (batch_size, 1, d_k)\n",
    "            K_io = self.fc_K_io(x) # (batch_size, n_atoms, d_k)\n",
    "            V_io = self.fc_V_io(x) # (batch_size, n_atoms, d_k)\n",
    "            a_io = self.att(Q_io, K_io, V_io)  # (batch_size, 1, d_k)\n",
    "            \n",
    "            xyz = self.fc_coords(a_io)\n",
    "            t = F.softmax(self.fc_types(a_io), dim=-1)\n",
    "\n",
    "            if temp:\n",
    "                xyz += temp * torch.randn(1, batch_size, 3, device=self.device)\n",
    "            \n",
    "            if self.var_coords:\n",
    "                z = torch.randn(1, batch_size, 3, device=self.device)\n",
    "                xyz += torch.exp(self.fc_coords_logstd(a_io).view(1, batch_size, 3)) * z\n",
    "            \n",
    "            coords = torch.cat((coords[:,:i,:], xyz, coords[:,i+1:,:]), dim=1)\n",
    "            types = torch.cat((types[:,:i,:], t, types[:,i+1:,:]), dim=1)\n",
    "            \n",
    "            xyzt = torch.cat((xyz, t), dim=-1)\n",
    "            ct = torch.cat((coords, types), dim=-1)\n",
    "        \n",
    "        return coords, types\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    def forward(self, Q, K, V):\n",
    "        d_k = K.shape[2]\n",
    "        QKT = torch.bmm(Q, K.transpose(1, 2))\n",
    "        return torch.bmm(F.softmax(QKT / np.sqrt(d_k), dim=2), V)\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for p in m.parameters():\n",
    "            nn.init.uniform_(p.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 4)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def write_xyz_and_arrows(types, coords, dcoords, out, out2, sample=False, state=0, scale=1):\n",
    "    '''\n",
    "    From BxNxT array of types, BxNx3 array of coords, and BxNx3 gradient,\n",
    "    generate a multi model xyz file (plus gradient) and a pymol script of\n",
    "    gradient arrows. Optionally sample atom type vector instead of max.\n",
    "    '''\n",
    "    i = 0\n",
    "    for ts, xyzs, dxyzs in zip(types, coords, dcoords):\n",
    "        out.write('{:d}\\n\\n'.format(len(ts)))\n",
    "        \n",
    "        j = 0\n",
    "        for t, (x,y,z), (dx,dy,dz) in zip(ts, xyzs, dxyzs):\n",
    "        \n",
    "            if sample:\n",
    "                elem = np.random.choice(elems, p=t)\n",
    "            else:\n",
    "                elem = elems[np.argmax(t)]\n",
    "\n",
    "            out.write('{:s}   {:f}  {:f}  {:f}  {:f}  {:f}  {:f}\\n'.format(elem,x,y,z,dx,dy,dz))\n",
    "            \n",
    "            x2 = x + scale*dx\n",
    "            y2 = y + scale*dy\n",
    "            z2 = z + scale*dz\n",
    "            out2.write('cgo_arrow [{}, {}, {}], [{}, {}, {}]'.format(x,y,z,x2,y2,z2) + \n",
    "                       ', name=arrow_{}_{}, state={}, color=black'.format(i, j, state) +\n",
    "                       ', radius=0.05, hradius=0.1, hlength=0.25\\n')\n",
    "            j += 1\n",
    "        i += 1\n",
    "    \n",
    "def out_of_box_loss(c, max_val):\n",
    "    '''hingey loss at box boundaries'''\n",
    "    return (F.relu(abs(c)-max_val)).sum()\n",
    "\n",
    "def grad_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1/2)\n",
    "    return total_norm\n",
    "\n",
    "def get_ylim(vals):\n",
    "    min_val = 0 #min(vals)\n",
    "    max_val = max(vals)\n",
    "    val_range = max_val - min_val\n",
    "    return min_val - 0.1*val_range, max_val + 0.1*val_range\n",
    "\n",
    "x_min, x_max = np.array([-15, 15])\n",
    "y_min, y_max = np.array([-1, 4])\n",
    "max_val = 23.5/2\n",
    "x = torch.arange(x_min, x_max, 0.01)\n",
    "y = torch.tensor([out_of_box_loss(x_, max_val) for x_ in x])\n",
    "plt.figure()\n",
    "plt.ylabel('out-of-box loss')\n",
    "plt.xlabel('position')\n",
    "plt.hlines(0, x_min, x_max, 'k', lw=1)\n",
    "plt.vlines(0, y_min, y_max, 'k', lw=1)\n",
    "plt.vlines([-max_val, max_val], y_min, y_max, 'r', 'dashed', lw=1)\n",
    "plt.plot(x, y, 'b', lw=2)\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]]], device='cuda:0')\n",
      "tensor([[[-0.1275, -0.0795, -0.0081],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0', grad_fn=<CatBackward>)\n",
      "tensor([[[-0.1275, -0.0795, -0.0081],\n",
      "         [-0.1275, -0.0795, -0.0081]]], device='cuda:0', grad_fn=<CatBackward>)\n",
      "Error in callback <function flush_figures at 0x7f84f58dad90> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/mtr22/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2057\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[0;32m--> 532\u001b[0;31m                                self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "n_atoms = 2\n",
    "n_latent = 1024\n",
    "rotate = False\n",
    "temp = 0.0\n",
    "\n",
    "gmaker = molgrid.GridMaker(resolution=0.5,\n",
    "                           dimension=23.5,\n",
    "                           radius_scale=1,\n",
    "                           radius_type_indexed=True)\n",
    "\n",
    "dims = gmaker.grid_dimensions(n_types)\n",
    "grid_size = dims[0] * dims[1] * dims[2] * dims[3]\n",
    "\n",
    "c2grid = molgrid.Coords2Grid(gmaker, center=(0,0,0))\n",
    "\n",
    "model = MolgridAttn(n_atoms, n_types, dims, n_latent, var_coords=False).to(device)\n",
    "model.apply(weight_init)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "lr_policy = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5)\n",
    "\n",
    "losses = []\n",
    "grid_losses = []\n",
    "oob_losses = []\n",
    "type_losses = []\n",
    "type_entropies = []\n",
    "grad_norms = []\n",
    "lrs = []\n",
    "\n",
    "loss_out = open('loss.txt', 'wt')\n",
    "pred_out = open('pred.xyz', 'wt')\n",
    "arrows_out = open('pred_arrows.pymol', 'wt')\n",
    "\n",
    "batch_size = 1\n",
    "n_iterations = 1\n",
    "step_interval = 10000\n",
    "print_interval = 1\n",
    "\n",
    "grid_true = torch.empty(batch_size, *dims, dtype=torch.float32, device=device)\n",
    "type_count_true = torch.empty(batch_size, n_types, dtype=torch.float32, device=device)\n",
    "batch_radii = torch.tensor(np.tile(radii, (batch_size, 1)), dtype=torch.float32, device=device)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, sharex=True, squeeze=True, figsize=(16, 5), gridspec_kw=dict(wspace=0.25))\n",
    "ax[0].plot(grid_losses, label='grid loss')\n",
    "ax[0].plot(oob_losses, label='oob loss')\n",
    "ax[0].plot(type_losses, label='type loss')\n",
    "ax[0].plot(type_entropies, label='type entropy')\n",
    "ax[0].legend(loc=0)\n",
    "ax[0].set_xlabel('iteration')\n",
    "ax[1].plot(grad_norms, label='gradient norm')\n",
    "ax[1].legend(loc=0)\n",
    "ax[1].set_xlabel('iteration')\n",
    "ax[2].plot(lrs, label='learning rate')\n",
    "ax[2].legend(loc=0)\n",
    "ax[2].set_xlabel('iteration')\n",
    "\n",
    "i = 0\n",
    "while i < n_iterations:\n",
    "    try:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = data_loader.next_batch(batch_size)\n",
    "        batch.sum_types(type_count_true)\n",
    "\n",
    "        gmaker.forward(batch, grid_true, random_rotation=rotate)\n",
    "        coords, typesd = model(grid_true, temp)\n",
    "        types = typesd[:,:,:-1].clone()\n",
    "        grid_gen = c2grid(coords, types, batch_radii)\n",
    "\n",
    "        type_entropy = -torch.sum(typesd * torch.log(typesd)) / (batch_size * n_atoms)\n",
    "        grid_loss = F.mse_loss(grid_true, grid_gen)\n",
    "        oob_loss  = out_of_box_loss(coords, max_val=11.5)\n",
    "        type_loss = F.mse_loss(type_count_true, types.sum(dim=1))\n",
    "        \n",
    "        if i == 0:\n",
    "            k_grid_loss    = 1/float(grid_loss)\n",
    "            k_oob_loss     = 1/100\n",
    "            k_type_loss    = 1/float(type_loss)\n",
    "            k_type_entropy = 0/float(type_entropy)\n",
    "\n",
    "        grid_loss    *= k_grid_loss\n",
    "        oob_loss     *= k_oob_loss\n",
    "        type_loss    *= k_type_loss\n",
    "        type_entropy *= k_type_entropy\n",
    "        \n",
    "        loss = grid_loss + oob_loss + type_loss + type_entropy\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
    "\n",
    "        losses.append(float(loss))\n",
    "        grid_losses.append(float(grid_loss))\n",
    "        oob_losses.append(float(oob_loss))\n",
    "        type_losses.append(float(type_loss))\n",
    "        type_entropies.append(float(type_entropy))\n",
    "        grad_norms.append(float(grad_norm(model)))\n",
    "        lrs.append(float(optimizer.param_groups[0]['lr']))\n",
    "        \n",
    "        if np.isnan(grad_norms[-1]):\n",
    "            print('grad_norm is nan')\n",
    "            break\n",
    "            \n",
    "        if np.isinf(grad_norms[-1]):\n",
    "            print('grad_norm is inf')\n",
    "            break\n",
    "\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "        row = (i, losses[-1], grid_losses[-1], oob_losses[-1], type_losses[-1], grad_norms[-1])\n",
    "        loss_out.write('%i %f %f %f %f %f\\n' % row)\n",
    "        loss_out.flush()\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            #print('[%i] loss=%f, grid_loss=%f, oob_loss=%f, type_loss=%f, grad_norm=%f' % row)\n",
    "\n",
    "            if True: # dynamic plotting\n",
    "                ax[0].get_lines()[0].set_data(range(i), grid_losses)\n",
    "                ax[0].get_lines()[1].set_data(range(i), oob_losses)\n",
    "                ax[0].get_lines()[2].set_data(range(i), type_losses)\n",
    "                ax[0].get_lines()[3].set_data(range(i), type_entropies)\n",
    "                ax[0].set_xlim(0, i)\n",
    "                ax[0].set_ylim(get_ylim(grid_losses + oob_losses + type_losses + type_entropies))\n",
    "\n",
    "                ax[1].get_lines()[0].set_data(range(i), grad_norms)\n",
    "                ax[1].set_xlim(0, i)\n",
    "                ax[1].set_ylim(get_ylim(grad_norms))\n",
    "\n",
    "                ax[2].get_lines()[0].set_data(range(i), lrs)\n",
    "                ax[2].set_xlim(0, i)\n",
    "                ax[2].set_ylim(get_ylim(lrs))\n",
    "\n",
    "                display.display(fig)\n",
    "                display.clear_output(wait=True)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            gmaker.forward(batch, grid_true, random_rotation=False)\n",
    "            coords, typesd = model(grid_true)\n",
    "            coords.retain_grad()\n",
    "            types = typesd[:,:,:-1].clone()\n",
    "            grid_gen = c2grid(coords, types, batch_radii)\n",
    "\n",
    "            type_entropy = -torch.sum(typesd * torch.log(typesd)) / (batch_size * n_atoms)\n",
    "            grid_loss = F.mse_loss(grid_true, grid_gen)\n",
    "            oob_loss  = out_of_box_loss(coords, max_val=11.5)\n",
    "            type_loss = F.mse_loss(type_count_true, types.sum(dim=1))\n",
    "            \n",
    "            grid_loss    *= k_grid_loss\n",
    "            oob_loss     *= k_oob_loss\n",
    "            type_loss    *= k_type_loss\n",
    "            type_entropy *= k_type_entropy\n",
    "            loss = grid_loss + oob_loss + type_loss + type_entropy\n",
    "            \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
    "\n",
    "            write_xyz_and_arrows(\n",
    "                typesd.detach().cpu().numpy()[:1,:,:],\n",
    "                coords.detach().cpu().numpy()[:1,:,:],\n",
    "                coords.grad.detach().cpu().numpy()[:1,:,:],\n",
    "                pred_out, arrows_out, sample=True,\n",
    "                state=i//print_interval,\n",
    "                scale=-500)\n",
    "            pred_out.flush()\n",
    "            arrows_out.flush()\n",
    "\n",
    "            if grad_norms[-1] < 5e-4:\n",
    "                print('converged')\n",
    "                break\n",
    "\n",
    "        if i % step_interval == 0:\n",
    "            lr_policy.step()\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2251.27487718632 0.01 0.37133895973486514 0.0\n"
     ]
    }
   ],
   "source": [
    "print(k_grid_loss, k_oob_loss, k_type_loss, k_type_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
